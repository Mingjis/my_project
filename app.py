import streamlit as st
import torch
import joblib
from transformers import ElectraTokenizer, ElectraModel
import os
import requests
import re

class KoELECTRAClassifier(torch.nn.Module):
    def __init__(self, electra, output_size):
        super(KoELECTRAClassifier, self).__init__()
        self.electra = electra
        self.fc = torch.nn.Linear(electra.config.hidden_size, output_size)

    def forward(self, input_ids, attention_mask):
        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.last_hidden_state[:, 0, :]
        return self.fc(pooled_output)

@st.cache_resource
def load_model():
    """GitHub Releasesì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í›„ ë¡œë“œ"""
    save_path = "fine_tuned_model.pt"
    github_download_url = "https://github.com/Mingjis/my_project/releases/download/v1.0/fine_tuned_model.pt"

    if not os.path.exists(save_path):
        st.write("ğŸ“¥ ëª¨ë¸ì„ GitHub Releasesì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        response = requests.get(github_download_url, stream=True)
        response.raise_for_status()
        with open(save_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        st.write("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

    try:
        electra_model = ElectraModel.from_pretrained("monologg/koelectra-base-v3-discriminator")
        model = KoELECTRAClassifier(electra=electra_model, output_size=412)

        model = torch.load(save_path, map_location="cpu")
        model.eval()
        return model
    except RuntimeError as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def load_law_details():
    """ law_details.txt íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë²•ë ¹ëª…ê³¼ ë²•ë ¹ ë‚´ìš©ì„ ë§¤í•‘ """
    law_dict = {}
    details_path = "law_details.txt"

    if os.path.exists(details_path):
        with open(details_path, "r", encoding="utf-8") as f:
            for line in f:
                if " , " in line:
                    key, value = line.split(" , ", 1)
                    key = key.strip() + " "
                    law_dict[key] = value.strip()
    return law_dict

model = load_model()
tokenizer = ElectraTokenizer.from_pretrained("monologg/koelectra-base-v3-discriminator")
label_encoder = joblib.load("label_encoder.pkl")
law_details = load_law_details()

st.title("Safety Legislation Recommendation for DfS report")

physical_risk = st.text_input("ë¬¼ì  ìœ„í—˜ì„±(í•„ìˆ˜) :")
human_risk = st.text_input("ì¸ì  ìœ„í—˜ì„±(í•„ìˆ˜) :")
keyword1 = st.text_input("Keyword 1(í•„ìˆ˜) :")
keyword2 = st.text_input("Keyword 2(ì„ íƒ) :")
keyword3 = st.text_input("Keyword 3(ì„ íƒ) :")

if st.button("Search"):
    keywords = [keyword1, keyword2, keyword3]
    input_text = f"{physical_risk} {human_risk} " + " ".join([k for k in keywords if k])

    inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True, max_length=64)

    with torch.no_grad():
        logits = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])
        probs = torch.nn.functional.softmax(logits, dim=1)
        top_k_probs, top_k_indices = torch.topk(probs, k=3, dim=1)

    top_k_indices = top_k_indices.squeeze().tolist()
    if not isinstance(top_k_indices, list):
        top_k_indices = [top_k_indices]

    predicted_laws = label_encoder.inverse_transform(top_k_indices)

    unique_laws = set()
    final_laws = []

    for law in predicted_laws:
        split_laws = re.split(r"(?=ì œ\d+ì¡°)", law)
        for l in split_laws:
            cleaned_law = l.strip()
            if cleaned_law and cleaned_law not in unique_laws:
                unique_laws.add(cleaned_law)
                final_laws.append(cleaned_law)

    st.subheader("List of Recommendation:")
    for i, law in enumerate(final_laws, start=1):
        cleaned_law = law.strip() + " "

        if cleaned_law in law_details:
            law_detail = law_details[cleaned_law]
        else:
            st.write(f"ğŸ” '{cleaned_law}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŒ â†’ law_details.keys()ì™€ ë¹„êµ í•„ìš”")
            st.write(f"ğŸ” í˜„ì¬ ì €ì¥ëœ í‚¤ ê°’ ìƒ˜í”Œ: {list(law_details.keys())[:10]}")
            law_detail = "ê´€ë ¨ ë‚´ìš© ì—†ìŒ"

        st.write(f"{i}. {cleaned_law} - {law_detail}")
